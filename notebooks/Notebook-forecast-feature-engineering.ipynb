{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Purpose:** This notebook uses machine learning to forecast the future performance of a stock to be used as features in a downstream classifier\n",
    "\n",
    "\n",
    "**Description:** Code will read in the base data file and create a series of forecasts, pick the best ones and use as features\n",
    "\n",
    "**Prerequisites:**\n",
    "- Environment: kedro-test (Python 3.10.16)\n",
    "- Required data: Base machine learning dataset for modeling\n",
    "- Key dependencies: Pandas, Sklearn\n",
    "\n",
    "**Inputs:** see above\n",
    "\n",
    "\n",
    "**Outputs:** [Generated files and artifacts]\n",
    "\n",
    "**Usage:**\n",
    "1. Ensure prerequisites are met\n",
    "2. Verify input data availability\n",
    "3. Run cells sequentially\n",
    "4. Check outputs in specified directories\n",
    "\n",
    "**⚠️ Notes:** [Any important warnings or considerations]\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Optional\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# functions:\n",
    "\n",
    "def make_sliding_window_split_df(df: pd.DataFrame, group_col: str, time_col: str, window_size: int, horizon: int = 1, step: int = 1, max_splits: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate sliding window train/test splits for time series data grouped by a key column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Original dataframe containing the time series data.\n",
    "        group_col (str): Name of the column to group by (e.g., ticker symbol).\n",
    "        time_col (str): Name of the datetime column used for sorting within groups.\n",
    "        window_size (int): Number of consecutive days used for the training window.\n",
    "        horizon (int, optional): Number of days to forecast in the test window. Defaults to 1.\n",
    "        step (int, optional): Number of days to move the sliding window forward each iteration. Defaults to 1.\n",
    "        max_splits (int, optional): Maximum number of splits to generate per group. Defaults to None (no limit).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame where each row represents a train/test split with columns:\n",
    "            - 'ticker': Group value (e.g., stock ticker).\n",
    "            - 'split_id': Integer split index within each group.\n",
    "            - 'train_start': Start date of training window.\n",
    "            - 'train_end': End date of training window.\n",
    "            - 'test_start': Start date of testing window.\n",
    "            - 'test_end': End date of testing window.\n",
    "            - 'train_idx': List of original dataframe indices used for training.\n",
    "            - 'test_idx': List of original dataframe indices used for testing.\n",
    "            - 'horizon': Number of days forecasted (test window size).\n",
    "            - 'window_size': Number of days in training window.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_values([group_col, time_col]).reset_index(drop=False)\n",
    "    full_idx = df['index'].values  # preserve original indices\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for group_val, group_df in df.groupby(group_col):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        group_indices = group_df.index.to_numpy()\n",
    "        n_samples = len(group_df)\n",
    "        split_count = 0\n",
    "\n",
    "        for start in range(0, n_samples - window_size - horizon + 1, step):\n",
    "            if max_splits is not None and split_count >= max_splits:\n",
    "                break\n",
    "\n",
    "            train_idx = group_indices[start : start + window_size]\n",
    "            test_idx = group_indices[start + window_size : start + window_size + horizon]\n",
    "\n",
    "            records.append({\n",
    "                'ticker': group_val,\n",
    "                'split_id': split_count,\n",
    "                'train_start': group_df.loc[train_idx[0], time_col],\n",
    "                'train_end': group_df.loc[train_idx[-1], time_col],\n",
    "                'test_start': group_df.loc[test_idx[0], time_col],\n",
    "                'test_end': group_df.loc[test_idx[-1], time_col],\n",
    "                'train_idx': full_idx[train_idx].tolist(),\n",
    "                'test_idx': full_idx[test_idx].tolist(),\n",
    "                'horizon': horizon,\n",
    "                'window_size': window_size\n",
    "            })\n",
    "\n",
    "            split_count += 1\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# parameters:\n",
    "parameters = {\n",
    "    'group_col' : 'ticker',\n",
    "    'time_col' : 'date', \n",
    "    'training_days' : 150,\n",
    "    'forecast_horizon' : 30,\n",
    "    'step' : 1,\n",
    "    'max_windows_per_group' : None,\n",
    "    'with_replacement' : True,\n",
    "    'target_variable'  : 'adj_close',\n",
    "    # specify the time series arguments to be used:\n",
    "    'arima_order' : [1, 1, 2]\n",
    "    \n",
    "    }  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import data:\n",
    "\n",
    "df = pd.read_csv('../data/03_primary/combined_modeling_input.csv')\n",
    "\n",
    "# Update data types:\n",
    "# make sure date types are correct:\n",
    "df['date'] = pd.to_datetime(df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>7_close_sma</th>\n",
       "      <th>14_close_sma</th>\n",
       "      <th>...</th>\n",
       "      <th>cum_days_above_above_14_close_sma_ind</th>\n",
       "      <th>cum_days_above_above_21_close_sma_ind</th>\n",
       "      <th>upper_bollinger_band</th>\n",
       "      <th>lower_bollinger_band</th>\n",
       "      <th>bol_pct_from_top</th>\n",
       "      <th>bol_pct_from_bottom</th>\n",
       "      <th>bol_range</th>\n",
       "      <th>bol_range_pct</th>\n",
       "      <th>target_20_days_ahead</th>\n",
       "      <th>target_20_days_ahead_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>38.722500</td>\n",
       "      <td>39.712502</td>\n",
       "      <td>38.557499</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>37.750080</td>\n",
       "      <td>148158800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.610001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>35.994999</td>\n",
       "      <td>36.430000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.547501</td>\n",
       "      <td>33.989902</td>\n",
       "      <td>365248800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.630001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>36.132500</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>37.064999</td>\n",
       "      <td>35.440895</td>\n",
       "      <td>234428400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.812500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>37.174999</td>\n",
       "      <td>37.207500</td>\n",
       "      <td>36.474998</td>\n",
       "      <td>36.982498</td>\n",
       "      <td>35.362019</td>\n",
       "      <td>219111200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.544998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>37.389999</td>\n",
       "      <td>37.955002</td>\n",
       "      <td>37.130001</td>\n",
       "      <td>37.687500</td>\n",
       "      <td>36.036129</td>\n",
       "      <td>164101200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.560001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       open       high        low      close  adj_close  \\\n",
       "0 2019-01-02  38.722500  39.712502  38.557499  39.480000  37.750080   \n",
       "1 2019-01-03  35.994999  36.430000  35.500000  35.547501  33.989902   \n",
       "2 2019-01-04  36.132500  37.137501  35.950001  37.064999  35.440895   \n",
       "3 2019-01-07  37.174999  37.207500  36.474998  36.982498  35.362019   \n",
       "4 2019-01-08  37.389999  37.955002  37.130001  37.687500  36.036129   \n",
       "\n",
       "      volume ticker  7_close_sma  14_close_sma  ...  \\\n",
       "0  148158800   AAPL          NaN           NaN  ...   \n",
       "1  365248800   AAPL          NaN           NaN  ...   \n",
       "2  234428400   AAPL          NaN           NaN  ...   \n",
       "3  219111200   AAPL          NaN           NaN  ...   \n",
       "4  164101200   AAPL          NaN           NaN  ...   \n",
       "\n",
       "   cum_days_above_above_14_close_sma_ind  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   cum_days_above_above_21_close_sma_ind  upper_bollinger_band  \\\n",
       "0                                    0.0                   NaN   \n",
       "1                                    0.0                   NaN   \n",
       "2                                    0.0                   NaN   \n",
       "3                                    0.0                   NaN   \n",
       "4                                    0.0                   NaN   \n",
       "\n",
       "   lower_bollinger_band  bol_pct_from_top  bol_pct_from_bottom  bol_range  \\\n",
       "0                   NaN               NaN                  NaN        NaN   \n",
       "1                   NaN               NaN                  NaN        NaN   \n",
       "2                   NaN               NaN                  NaN        NaN   \n",
       "3                   NaN               NaN                  NaN        NaN   \n",
       "4                   NaN               NaN                  NaN        NaN   \n",
       "\n",
       "   bol_range_pct  target_20_days_ahead  target_20_days_ahead_ind  \n",
       "0            NaN             41.610001                         1  \n",
       "1            NaN             41.630001                         1  \n",
       "2            NaN             42.812500                         1  \n",
       "3            NaN             43.544998                         1  \n",
       "4            NaN             43.560001                         1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>split_id</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>train_idx</th>\n",
       "      <th>test_idx</th>\n",
       "      <th>horizon</th>\n",
       "      <th>window_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>XLF</td>\n",
       "      <td>739</td>\n",
       "      <td>2021-12-07</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>2022-07-14</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>[739, 740, 741, 742, 743, 744, 745, 746, 747, ...</td>\n",
       "      <td>[889, 890, 891, 892, 893, 894, 895, 896, 897, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>XLF</td>\n",
       "      <td>740</td>\n",
       "      <td>2021-12-08</td>\n",
       "      <td>2022-07-14</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>2022-08-25</td>\n",
       "      <td>[740, 741, 742, 743, 744, 745, 746, 747, 748, ...</td>\n",
       "      <td>[890, 891, 892, 893, 894, 895, 896, 897, 898, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>XLF</td>\n",
       "      <td>741</td>\n",
       "      <td>2021-12-09</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>2022-08-26</td>\n",
       "      <td>[741, 742, 743, 744, 745, 746, 747, 748, 749, ...</td>\n",
       "      <td>[891, 892, 893, 894, 895, 896, 897, 898, 899, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>XLF</td>\n",
       "      <td>742</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>2022-07-19</td>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>[742, 743, 744, 745, 746, 747, 748, 749, 750, ...</td>\n",
       "      <td>[892, 893, 894, 895, 896, 897, 898, 899, 900, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>XLF</td>\n",
       "      <td>743</td>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>2022-07-19</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>[743, 744, 745, 746, 747, 748, 749, 750, 751, ...</td>\n",
       "      <td>[893, 894, 895, 896, 897, 898, 899, 900, 901, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker  split_id train_start  train_end test_start   test_end  \\\n",
       "2227    XLF       739  2021-12-07 2022-07-13 2022-07-14 2022-08-24   \n",
       "2228    XLF       740  2021-12-08 2022-07-14 2022-07-15 2022-08-25   \n",
       "2229    XLF       741  2021-12-09 2022-07-15 2022-07-18 2022-08-26   \n",
       "2230    XLF       742  2021-12-10 2022-07-18 2022-07-19 2022-08-29   \n",
       "2231    XLF       743  2021-12-13 2022-07-19 2022-07-20 2022-08-30   \n",
       "\n",
       "                                              train_idx  \\\n",
       "2227  [739, 740, 741, 742, 743, 744, 745, 746, 747, ...   \n",
       "2228  [740, 741, 742, 743, 744, 745, 746, 747, 748, ...   \n",
       "2229  [741, 742, 743, 744, 745, 746, 747, 748, 749, ...   \n",
       "2230  [742, 743, 744, 745, 746, 747, 748, 749, 750, ...   \n",
       "2231  [743, 744, 745, 746, 747, 748, 749, 750, 751, ...   \n",
       "\n",
       "                                               test_idx  horizon  window_size  \n",
       "2227  [889, 890, 891, 892, 893, 894, 895, 896, 897, ...       30          150  \n",
       "2228  [890, 891, 892, 893, 894, 895, 896, 897, 898, ...       30          150  \n",
       "2229  [891, 892, 893, 894, 895, 896, 897, 898, 899, ...       30          150  \n",
       "2230  [892, 893, 894, 895, 896, 897, 898, 899, 900, ...       30          150  \n",
       "2231  [893, 894, 895, 896, 897, 898, 899, 900, 901, ...       30          150  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# define the training and test split windows:\n",
    "\n",
    "\n",
    "df_split = make_sliding_window_split_df(df = df, group_col = 'ticker', time_col = 'date', window_size = 150, horizon = 30, step = 1, max_splits = None)\n",
    "\n",
    "# check the split:\n",
    "df_split.head()\n",
    "\n",
    "# check the split:\n",
    "df_split.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def train_time_series_models(df: pd.DataFrame, splits: pd.DataFrame, parameters: dict) -> pd.DataFrame:\n",
    "\n",
    "    ''' Modeling for the time series features to go into the model; we will start with a simple ARIMA for this\n",
    "\n",
    "    Args:\n",
    "        df: Dataframe containing the time series data\n",
    "        splits: dataframe containing the splits for the time series data\n",
    "        parameters: dictionary containing the parameters for the model\n",
    "\n",
    "    Returns:\n",
    "        dataframe containing the model results\n",
    "\n",
    "    '''\n",
    "    #TODO - add in autoa arima capability for the FE step\n",
    "\n",
    "    split_test = splits[0:1]\n",
    "    print(split_test)\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    for index, split in split_test.iterrows():\n",
    "        # set variables for the split:\n",
    "        ticker = split['ticker']\n",
    "        train_start = pd.to_datetime(split['train_start'])\n",
    "        train_end = pd.to_datetime(split['train_end'])\n",
    "\n",
    "        # create a training set for each split:\n",
    "        training_set = df[(df['ticker'] == ticker) &\n",
    "                      (df['date'] >= train_start) & \n",
    "                      (df['date'] <= train_end)]\n",
    "        # set the training time series for the ARIMA:\n",
    "        train_ts = training_set.set_index('date')['adj_close']\n",
    "\n",
    "        # create a test set for each split:\n",
    "        training_set = df[(df['ticker'] == ticker) &\n",
    "                      (df['date'] >= train_start) & \n",
    "                      (df['date'] <= train_end)]\n",
    "        # set the test time series for the ARIMA:\n",
    "        train_ts = training_set.set_index('date')['adj_close']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # create a test set for each split:\n",
    "\n",
    "        #test_set = df[df['ticker'] == split['ticker'] & df['date'] >= split['test_start'] & df['date'] <= split['test_end']]\n",
    "\n",
    "        # predict the future for the test set:\n",
    "        #model = ARIMA(training_set[parameters['target_variable']], order=parameters['arima_order'])\n",
    "       \n",
    "        #predictions = model_fit.predict(start=training_set['train_start'], end=training_set['train_end'], dynamic=False)\n",
    "\n",
    "        # add the predictions to the test set:\n",
    "        \n",
    "\n",
    "    \n",
    "    return training_set\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker  split_id train_start  train_end test_start   test_end  \\\n",
      "0   AAPL         0  2019-01-02 2019-08-06 2019-08-07 2019-09-18   \n",
      "\n",
      "                                           train_idx  \\\n",
      "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "\n",
      "                                            test_idx  horizon  window_size  \n",
      "0  [150, 151, 152, 153, 154, 155, 156, 157, 158, ...       30          150  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>7_close_sma</th>\n",
       "      <th>14_close_sma</th>\n",
       "      <th>...</th>\n",
       "      <th>cum_days_above_above_14_close_sma_ind</th>\n",
       "      <th>cum_days_above_above_21_close_sma_ind</th>\n",
       "      <th>upper_bollinger_band</th>\n",
       "      <th>lower_bollinger_band</th>\n",
       "      <th>bol_pct_from_top</th>\n",
       "      <th>bol_pct_from_bottom</th>\n",
       "      <th>bol_range</th>\n",
       "      <th>bol_range_pct</th>\n",
       "      <th>target_20_days_ahead</th>\n",
       "      <th>target_20_days_ahead_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>38.722500</td>\n",
       "      <td>39.712502</td>\n",
       "      <td>38.557499</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>37.750080</td>\n",
       "      <td>148158800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.610001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>35.994999</td>\n",
       "      <td>36.430000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.547501</td>\n",
       "      <td>33.989902</td>\n",
       "      <td>365248800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.630001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>36.132500</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>37.064999</td>\n",
       "      <td>35.440895</td>\n",
       "      <td>234428400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.812500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>37.174999</td>\n",
       "      <td>37.207500</td>\n",
       "      <td>36.474998</td>\n",
       "      <td>36.982498</td>\n",
       "      <td>35.362019</td>\n",
       "      <td>219111200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.544998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>37.389999</td>\n",
       "      <td>37.955002</td>\n",
       "      <td>37.130001</td>\n",
       "      <td>37.687500</td>\n",
       "      <td>36.036129</td>\n",
       "      <td>164101200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.560001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>54.105000</td>\n",
       "      <td>55.342499</td>\n",
       "      <td>52.825001</td>\n",
       "      <td>53.259998</td>\n",
       "      <td>51.341656</td>\n",
       "      <td>277125600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>52.277500</td>\n",
       "      <td>51.707143</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>52.980339</td>\n",
       "      <td>49.715137</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.071303</td>\n",
       "      <td>3.265203</td>\n",
       "      <td>0.061307</td>\n",
       "      <td>51.382500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>53.474998</td>\n",
       "      <td>54.507500</td>\n",
       "      <td>51.685001</td>\n",
       "      <td>52.107498</td>\n",
       "      <td>50.230667</td>\n",
       "      <td>216071600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>52.262857</td>\n",
       "      <td>51.798750</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>53.050522</td>\n",
       "      <td>49.780668</td>\n",
       "      <td>-0.017776</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>3.269854</td>\n",
       "      <td>0.062752</td>\n",
       "      <td>52.252499</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>51.382500</td>\n",
       "      <td>51.607498</td>\n",
       "      <td>50.407501</td>\n",
       "      <td>51.005001</td>\n",
       "      <td>49.167881</td>\n",
       "      <td>163448400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>52.096785</td>\n",
       "      <td>51.777500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.050162</td>\n",
       "      <td>49.771743</td>\n",
       "      <td>-0.038551</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>3.278419</td>\n",
       "      <td>0.064276</td>\n",
       "      <td>52.185001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>49.497501</td>\n",
       "      <td>49.662498</td>\n",
       "      <td>48.145000</td>\n",
       "      <td>48.334999</td>\n",
       "      <td>46.594040</td>\n",
       "      <td>209572000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>51.608214</td>\n",
       "      <td>51.578214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.398791</td>\n",
       "      <td>49.163828</td>\n",
       "      <td>-0.094830</td>\n",
       "      <td>-0.016859</td>\n",
       "      <td>4.234963</td>\n",
       "      <td>0.087617</td>\n",
       "      <td>51.424999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>49.077499</td>\n",
       "      <td>49.517502</td>\n",
       "      <td>48.509998</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>47.476089</td>\n",
       "      <td>143299200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>51.224642</td>\n",
       "      <td>51.464821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.476445</td>\n",
       "      <td>49.014270</td>\n",
       "      <td>-0.079034</td>\n",
       "      <td>0.004809</td>\n",
       "      <td>4.462175</td>\n",
       "      <td>0.090603</td>\n",
       "      <td>52.297501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date       open       high        low      close  adj_close  \\\n",
       "0   2019-01-02  38.722500  39.712502  38.557499  39.480000  37.750080   \n",
       "1   2019-01-03  35.994999  36.430000  35.500000  35.547501  33.989902   \n",
       "2   2019-01-04  36.132500  37.137501  35.950001  37.064999  35.440895   \n",
       "3   2019-01-07  37.174999  37.207500  36.474998  36.982498  35.362019   \n",
       "4   2019-01-08  37.389999  37.955002  37.130001  37.687500  36.036129   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "145 2019-07-31  54.105000  55.342499  52.825001  53.259998  51.341656   \n",
       "146 2019-08-01  53.474998  54.507500  51.685001  52.107498  50.230667   \n",
       "147 2019-08-02  51.382500  51.607498  50.407501  51.005001  49.167881   \n",
       "148 2019-08-05  49.497501  49.662498  48.145000  48.334999  46.594040   \n",
       "149 2019-08-06  49.077499  49.517502  48.509998  49.250000  47.476089   \n",
       "\n",
       "        volume ticker  7_close_sma  14_close_sma  ...  \\\n",
       "0    148158800   AAPL          NaN           NaN  ...   \n",
       "1    365248800   AAPL          NaN           NaN  ...   \n",
       "2    234428400   AAPL          NaN           NaN  ...   \n",
       "3    219111200   AAPL          NaN           NaN  ...   \n",
       "4    164101200   AAPL          NaN           NaN  ...   \n",
       "..         ...    ...          ...           ...  ...   \n",
       "145  277125600   AAPL    52.277500     51.707143  ...   \n",
       "146  216071600   AAPL    52.262857     51.798750  ...   \n",
       "147  163448400   AAPL    52.096785     51.777500  ...   \n",
       "148  209572000   AAPL    51.608214     51.578214  ...   \n",
       "149  143299200   AAPL    51.224642     51.464821  ...   \n",
       "\n",
       "     cum_days_above_above_14_close_sma_ind  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      0.0   \n",
       "..                                     ...   \n",
       "145                                    8.0   \n",
       "146                                    9.0   \n",
       "147                                    0.0   \n",
       "148                                    0.0   \n",
       "149                                    0.0   \n",
       "\n",
       "     cum_days_above_above_21_close_sma_ind  upper_bollinger_band  \\\n",
       "0                                      0.0                   NaN   \n",
       "1                                      0.0                   NaN   \n",
       "2                                      0.0                   NaN   \n",
       "3                                      0.0                   NaN   \n",
       "4                                      0.0                   NaN   \n",
       "..                                     ...                   ...   \n",
       "145                                   39.0             52.980339   \n",
       "146                                   40.0             53.050522   \n",
       "147                                    0.0             53.050162   \n",
       "148                                    0.0             53.398791   \n",
       "149                                    0.0             53.476445   \n",
       "\n",
       "     lower_bollinger_band  bol_pct_from_top  bol_pct_from_bottom  bol_range  \\\n",
       "0                     NaN               NaN                  NaN        NaN   \n",
       "1                     NaN               NaN                  NaN        NaN   \n",
       "2                     NaN               NaN                  NaN        NaN   \n",
       "3                     NaN               NaN                  NaN        NaN   \n",
       "4                     NaN               NaN                  NaN        NaN   \n",
       "..                    ...               ...                  ...        ...   \n",
       "145             49.715137          0.005279             0.071303   3.265203   \n",
       "146             49.780668         -0.017776             0.046742   3.269854   \n",
       "147             49.771743         -0.038551             0.024778   3.278419   \n",
       "148             49.163828         -0.094830            -0.016859   4.234963   \n",
       "149             49.014270         -0.079034             0.004809   4.462175   \n",
       "\n",
       "     bol_range_pct  target_20_days_ahead  target_20_days_ahead_ind  \n",
       "0              NaN             41.610001                         1  \n",
       "1              NaN             41.630001                         1  \n",
       "2              NaN             42.812500                         1  \n",
       "3              NaN             43.544998                         1  \n",
       "4              NaN             43.560001                         1  \n",
       "..             ...                   ...                       ...  \n",
       "145       0.061307             51.382500                         0  \n",
       "146       0.062752             52.252499                         1  \n",
       "147       0.064276             52.185001                         1  \n",
       "148       0.087617             51.424999                         1  \n",
       "149       0.090603             52.297501                         1  \n",
       "\n",
       "[150 rows x 31 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_time_series_models(df = df, splits = df_split, parameters = parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>7_close_sma</th>\n",
       "      <th>14_close_sma</th>\n",
       "      <th>...</th>\n",
       "      <th>cum_days_above_above_14_close_sma_ind</th>\n",
       "      <th>cum_days_above_above_21_close_sma_ind</th>\n",
       "      <th>upper_bollinger_band</th>\n",
       "      <th>lower_bollinger_band</th>\n",
       "      <th>bol_pct_from_top</th>\n",
       "      <th>bol_pct_from_bottom</th>\n",
       "      <th>bol_range</th>\n",
       "      <th>bol_range_pct</th>\n",
       "      <th>target_20_days_ahead</th>\n",
       "      <th>target_20_days_ahead_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>38.722500</td>\n",
       "      <td>39.712502</td>\n",
       "      <td>38.557499</td>\n",
       "      <td>39.480000</td>\n",
       "      <td>37.750080</td>\n",
       "      <td>148158800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.610001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>35.994999</td>\n",
       "      <td>36.430000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>35.547501</td>\n",
       "      <td>33.989902</td>\n",
       "      <td>365248800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.630001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>36.132500</td>\n",
       "      <td>37.137501</td>\n",
       "      <td>35.950001</td>\n",
       "      <td>37.064999</td>\n",
       "      <td>35.440895</td>\n",
       "      <td>234428400</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.812500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>37.174999</td>\n",
       "      <td>37.207500</td>\n",
       "      <td>36.474998</td>\n",
       "      <td>36.982498</td>\n",
       "      <td>35.362019</td>\n",
       "      <td>219111200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.544998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>37.389999</td>\n",
       "      <td>37.955002</td>\n",
       "      <td>37.130001</td>\n",
       "      <td>37.687500</td>\n",
       "      <td>36.036129</td>\n",
       "      <td>164101200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.560001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date       open       high        low      close  adj_close  \\\n",
       "0 2019-01-02  38.722500  39.712502  38.557499  39.480000  37.750080   \n",
       "1 2019-01-03  35.994999  36.430000  35.500000  35.547501  33.989902   \n",
       "2 2019-01-04  36.132500  37.137501  35.950001  37.064999  35.440895   \n",
       "3 2019-01-07  37.174999  37.207500  36.474998  36.982498  35.362019   \n",
       "4 2019-01-08  37.389999  37.955002  37.130001  37.687500  36.036129   \n",
       "\n",
       "      volume ticker  7_close_sma  14_close_sma  ...  \\\n",
       "0  148158800   AAPL          NaN           NaN  ...   \n",
       "1  365248800   AAPL          NaN           NaN  ...   \n",
       "2  234428400   AAPL          NaN           NaN  ...   \n",
       "3  219111200   AAPL          NaN           NaN  ...   \n",
       "4  164101200   AAPL          NaN           NaN  ...   \n",
       "\n",
       "   cum_days_above_above_14_close_sma_ind  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   cum_days_above_above_21_close_sma_ind  upper_bollinger_band  \\\n",
       "0                                    0.0                   NaN   \n",
       "1                                    0.0                   NaN   \n",
       "2                                    0.0                   NaN   \n",
       "3                                    0.0                   NaN   \n",
       "4                                    0.0                   NaN   \n",
       "\n",
       "   lower_bollinger_band  bol_pct_from_top  bol_pct_from_bottom  bol_range  \\\n",
       "0                   NaN               NaN                  NaN        NaN   \n",
       "1                   NaN               NaN                  NaN        NaN   \n",
       "2                   NaN               NaN                  NaN        NaN   \n",
       "3                   NaN               NaN                  NaN        NaN   \n",
       "4                   NaN               NaN                  NaN        NaN   \n",
       "\n",
       "   bol_range_pct  target_20_days_ahead  target_20_days_ahead_ind  \n",
       "0            NaN             41.610001                         1  \n",
       "1            NaN             41.630001                         1  \n",
       "2            NaN             42.812500                         1  \n",
       "3            NaN             43.544998                         1  \n",
       "4            NaN             43.560001                         1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "#train_time_series_models(df = df, splits = df_split, parameters = parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create baseline forecaster:\n",
    "\n",
    "def create_baseline_forecaster(df: pd.DataFrame, parameters: dict) -> pd.DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated training function with ARIMA PDQ selection\n",
    "def train_time_series_models_with_arima(df: pd.DataFrame, splits: pd.DataFrame, parameters: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Train ARIMA models with automatic PDQ selection\n",
    "    \n",
    "    Args:\n",
    "        df: Dataframe containing the time series data\n",
    "        splits: dataframe containing the splits for the time series data\n",
    "        parameters: dictionary containing the parameters for the model\n",
    "    \n",
    "    Returns:\n",
    "        dataframe containing the model results\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test on first few splits\n",
    "    split_test = splits.head(5)  # Start with 5 splits for testing\n",
    "    \n",
    "    for index, split in split_test.iterrows():\n",
    "        try:\n",
    "            # Get training data using the indices\n",
    "            train_indices = split['train_idx']\n",
    "            train_data = df.iloc[train_indices]\n",
    "            \n",
    "            # Focus on close price for ARIMA\n",
    "            price_series = train_data['close']\n",
    "            \n",
    "            # 1. Determine differencing order\n",
    "            d_order = determine_differencing_order(price_series)\n",
    "            print(f\"Ticker: {split['ticker']}, Split: {split['split_id']}, Suggested D: {d_order}\")\n",
    "            \n",
    "            # 2. Create focused PDQ grid around determined D\n",
    "            focused_pdq = []\n",
    "            for p in [0, 1, 2]:\n",
    "                for q in [0, 1, 2]:\n",
    "                    focused_pdq.append((p, d_order, q))\n",
    "            \n",
    "            # 3. Select best PDQ\n",
    "            best_pdq, best_model, best_aic = select_best_arima_pdq(price_series, focused_pdq)\n",
    "            \n",
    "            if best_pdq is not None and best_model is not None:\n",
    "                # 4. Make predictions\n",
    "                forecast_steps = split['horizon']\n",
    "                forecast = best_model.forecast(steps=forecast_steps)\n",
    "                \n",
    "                # Store results\n",
    "                results.append({\n",
    "                    'ticker': split['ticker'],\n",
    "                    'split_id': split['split_id'],\n",
    "                    'best_pdq': best_pdq,\n",
    "                    'aic': best_aic,\n",
    "                    'forecast_mean': forecast.mean(),\n",
    "                    'forecast_std': forecast.std(),\n",
    "                    'train_start': split['train_start'],\n",
    "                    'train_end': split['train_end'],\n",
    "                    'test_start': split['test_start'],\n",
    "                    'test_end': split['test_end']\n",
    "                })\n",
    "                \n",
    "                print(f\"Best PDQ: {best_pdq}, AIC: {best_aic:.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing split {split['split_id']}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the ARIMA PDQ selection\n",
    "print(\"Testing ARIMA PDQ Selection...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Install required package if not already installed\n",
    "try:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    print(\"✓ Statsmodels is available\")\n",
    "except ImportError:\n",
    "    print(\"❌ Please install statsmodels: pip install statsmodels\")\n",
    "\n",
    "# Run the ARIMA training\n",
    "try:\n",
    "    arima_results = train_time_series_models_with_arima(df=df, splits=df_split, parameters=parameters)\n",
    "    \n",
    "    # Display results\n",
    "    if not arima_results.empty:\n",
    "        print(\"\\nARIMA Results Summary:\")\n",
    "        print(arima_results[['ticker', 'split_id', 'best_pdq', 'aic', 'forecast_mean']].head(10))\n",
    "    else:\n",
    "        print(\"No results generated. Check for errors above.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error running ARIMA analysis: {e}\")\n",
    "    print(\"You may need to install statsmodels: pip install statsmodels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUTO ARIMA - Much Better Approach!\n",
    "# Install: pip install pmdarima\n",
    "\n",
    "def train_auto_arima_models(df: pd.DataFrame, splits: pd.DataFrame, parameters: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Train ARIMA models using auto_arima for automatic PDQ optimization\n",
    "    \n",
    "    Args:\n",
    "        df: Dataframe containing the time series data\n",
    "        splits: dataframe containing the splits for the time series data  \n",
    "        parameters: dictionary containing the parameters for the model\n",
    "    \n",
    "    Returns:\n",
    "        dataframe containing the model results\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        from pmdarima import auto_arima\n",
    "        print(\"✓ pmdarima is available\")\n",
    "    except ImportError:\n",
    "        print(\"❌ Please install pmdarima: pip install pmdarima\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Test on first few splits\n",
    "    split_test = splits.head(10)  # Test with 10 splits\n",
    "    \n",
    "    for index, split in split_test.iterrows():\n",
    "        try:\n",
    "            # Get training data using the indices\n",
    "            train_indices = split['train_idx']\n",
    "            train_data = df.iloc[train_indices]\n",
    "            \n",
    "            # Focus on target variable for ARIMA\n",
    "            target_col = parameters.get('target_variable', 'adj_close')\n",
    "            price_series = train_data[target_col].dropna()\n",
    "            \n",
    "            print(f\"\\\\nProcessing: {split['ticker']}, Split: {split['split_id']}\")\n",
    "            \n",
    "            # AUTO ARIMA - This does all the work!\n",
    "            auto_model = auto_arima(\n",
    "                price_series,\n",
    "                start_p=0, start_q=0,      # Starting values\n",
    "                max_p=3, max_q=3,          # Maximum values to test\n",
    "                seasonal=False,             # No seasonality for daily stock prices\n",
    "                stepwise=True,             # Use stepwise algorithm (faster)\n",
    "                suppress_warnings=True,\n",
    "                error_action='ignore',\n",
    "                trace=False                # Set to True to see search process\n",
    "            )\n",
    "            \n",
    "            # Get the optimal order\n",
    "            optimal_order = auto_model.order\n",
    "            aic_score = auto_model.aic()\n",
    "            \n",
    "            print(f\"Optimal PDQ: {optimal_order}, AIC: {aic_score:.2f}\")\n",
    "            \n",
    "            # Make predictions\n",
    "            forecast_steps = split['horizon']\n",
    "            forecast, conf_int = auto_model.predict(n_periods=forecast_steps, \n",
    "                                                   return_conf_int=True)\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'ticker': split['ticker'],\n",
    "                'split_id': split['split_id'],\n",
    "                'optimal_pdq': optimal_order,\n",
    "                'aic': aic_score,\n",
    "                'forecast_mean': forecast.mean(),\n",
    "                'forecast_std': forecast.std(),\n",
    "                'forecast_values': forecast.tolist(),\n",
    "                'confidence_lower': conf_int[:, 0].tolist(),\n",
    "                'confidence_upper': conf_int[:, 1].tolist(),\n",
    "                'train_start': split['train_start'],\n",
    "                'train_end': split['train_end'],\n",
    "                'test_start': split['test_start'],\n",
    "                'test_end': split['test_end'],\n",
    "                'train_size': len(price_series)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {split['ticker']} split {split['split_id']}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Auto ARIMA\n",
    "print(\"Testing Auto ARIMA...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Run the Auto ARIMA training\n",
    "try:\n",
    "    auto_arima_results = train_auto_arima_models(df=df, splits=df_split, parameters=parameters)\n",
    "    \n",
    "    # Display results\n",
    "    if not auto_arima_results.empty:\n",
    "        print(\"\\n🎯 Auto ARIMA Results Summary:\")\n",
    "        print(\"-\" * 40)\n",
    "        display_cols = ['ticker', 'split_id', 'optimal_pdq', 'aic', 'forecast_mean']\n",
    "        print(auto_arima_results[display_cols].head())\n",
    "        \n",
    "        # Show PDQ distribution\n",
    "        print(\"\\n📊 PDQ Parameter Distribution:\")\n",
    "        pdq_counts = auto_arima_results['optimal_pdq'].value_counts()\n",
    "        for pdq, count in pdq_counts.head(5).items():\n",
    "            print(f\"  {pdq}: {count} times\")\n",
    "            \n",
    "    else:\n",
    "        print(\"No results generated. Install pmdarima first.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"\\n💡 To use Auto ARIMA, install pmdarima:\")\n",
    "    print(\"    pip install pmdarima\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why Auto ARIMA is Better - Comparison\n",
    "\n",
    "print(\"🔄 ARIMA Optimization Methods Comparison\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\"\"\n",
    "📊 MANUAL GRID SEARCH (What we did before):\n",
    "   ❌ Tests all P,D,Q combinations (3×3×3 = 27 models)\n",
    "   ❌ Very slow for large datasets  \n",
    "   ❌ May miss optimal combinations\n",
    "   ❌ No intelligent search strategy\n",
    "   ❌ Fixed search space\n",
    "\n",
    "🚀 AUTO ARIMA (pmdarima package):\n",
    "   ✅ Uses stepwise algorithm - much faster\n",
    "   ✅ Automatically tests stationarity\n",
    "   ✅ Intelligent search with information criteria\n",
    "   ✅ Handles seasonality detection\n",
    "   ✅ Can expand search space if needed\n",
    "   ✅ Built-in model validation\n",
    "   \n",
    "💡 RECOMMENDED USAGE:\n",
    "\"\"\")\n",
    "\n",
    "code_example = '''\n",
    "# Simple Auto ARIMA\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "model = auto_arima(\n",
    "    price_series,\n",
    "    seasonal=False,     # For daily stock prices\n",
    "    stepwise=True,      # Fast stepwise algorithm  \n",
    "    suppress_warnings=True,\n",
    "    error_action='ignore'\n",
    ")\n",
    "\n",
    "optimal_pdq = model.order  # Gets best (p,d,q)\n",
    "'''\n",
    "\n",
    "print(code_example)\n",
    "\n",
    "print(\"\"\"\n",
    "🎯 KEY BENEFITS FOR STOCK FORECASTING:\n",
    "   • Automatically determines if differencing is needed (D parameter)\n",
    "   • Finds optimal P,Q without exhaustive search\n",
    "   • Much faster than grid search\n",
    "   • More robust model selection\n",
    "   • Handles edge cases automatically\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2769, 31)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>split_id</th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>train_idx</th>\n",
       "      <th>test_idx</th>\n",
       "      <th>horizon</th>\n",
       "      <th>window_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>2019-09-18</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[150, 151, 152, 153, 154, 155, 156, 157, 158, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>[151, 152, 153, 154, 155, 156, 157, 158, 159, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...</td>\n",
       "      <td>[152, 153, 154, 155, 156, 157, 158, 159, 160, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[153, 154, 155, 156, 157, 158, 159, 160, 161, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>2019-08-13</td>\n",
       "      <td>2019-09-24</td>\n",
       "      <td>[4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...</td>\n",
       "      <td>[154, 155, 156, 157, 158, 159, 160, 161, 162, ...</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker  split_id train_start  train_end test_start   test_end  \\\n",
       "0   AAPL         0  2019-01-02 2019-08-06 2019-08-07 2019-09-18   \n",
       "1   AAPL         1  2019-01-03 2019-08-07 2019-08-08 2019-09-19   \n",
       "2   AAPL         2  2019-01-04 2019-08-08 2019-08-09 2019-09-20   \n",
       "3   AAPL         3  2019-01-07 2019-08-09 2019-08-12 2019-09-23   \n",
       "4   AAPL         4  2019-01-08 2019-08-12 2019-08-13 2019-09-24   \n",
       "\n",
       "                                           train_idx  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
       "2  [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1...   \n",
       "3  [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, ...   \n",
       "4  [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,...   \n",
       "\n",
       "                                            test_idx  horizon  window_size  \n",
       "0  [150, 151, 152, 153, 154, 155, 156, 157, 158, ...       30          150  \n",
       "1  [151, 152, 153, 154, 155, 156, 157, 158, 159, ...       30          150  \n",
       "2  [152, 153, 154, 155, 156, 157, 158, 159, 160, ...       30          150  \n",
       "3  [153, 154, 155, 156, 157, 158, 159, 160, 161, ...       30          150  \n",
       "4  [154, 155, 156, 157, 158, 159, 160, 161, 162, ...       30          150  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
